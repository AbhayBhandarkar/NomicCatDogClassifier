{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mangalabhandarkar/Desktop/Zeroshotdetection/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoProcessor, AutoModel\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: einops in ./.venv/lib/python3.12/site-packages (0.8.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/nomic-ai/nomic-bert-2048:\n",
      "- configuration_hf_nomic_bert.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/nomic-ai/nomic-bert-2048:\n",
      "- modeling_hf_nomic_bert.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel\n",
    "from transformers import AutoProcessor\n",
    "# Load Nomic's Vision Embedding model\n",
    "def load_nomic_vision_model():\n",
    "    model = AutoModel.from_pretrained(\"nomic-ai/nomic-embed-vision-v1.5\", trust_remote_code=True)\n",
    "    processor = AutoProcessor.from_pretrained(\"nomic-ai/nomic-embed-vision-v1.5\", trust_remote_code=True)\n",
    "    return model, processor\n",
    "\n",
    "# Initialize the model and processor\n",
    "model, processor = load_nomic_vision_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(image_path, model, processor):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    inputs = processor(images=image, return_tensors=\"pt\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        features = model(**inputs).last_hidden_state.mean(dim=1)\n",
    "    \n",
    "    return features.squeeze().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_feature_vectors(support_set, model, processor):\n",
    "    class_features = {}\n",
    "    \n",
    "    for label, image_paths in support_set.items():\n",
    "        features = []\n",
    "        for img_path in image_paths:\n",
    "            feature = extract_features(img_path, model, processor)\n",
    "            features.append(feature)\n",
    "        class_features[label] = np.mean(features, axis=0)  # Average feature vector for class\n",
    "    \n",
    "    return class_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "def rank_classes(query_image_path, class_features, model, processor):\n",
    "    query_feature = extract_features(query_image_path, model, processor)\n",
    "\n",
    "    scores = {}\n",
    "    for label, avg_feature in class_features.items():\n",
    "        similarity = cosine_similarity(query_feature, avg_feature)\n",
    "        scores[label] = similarity\n",
    "\n",
    "    ranked_classes = sorted(scores, key=scores.get, reverse=True)\n",
    "    return ranked_classes, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_shot_classification(support_set, query_image_path, model, processor):\n",
    "    # Step 3: Get average feature vectors for the support set\n",
    "    class_features = get_average_feature_vectors(support_set, model, processor)\n",
    "    \n",
    "    # Step 4: Rank classes by similarity to the query image\n",
    "    ranked_classes, scores = rank_classes(query_image_path, class_features, model, processor)\n",
    "    \n",
    "    # Step 5: Return the class with the highest score\n",
    "    return ranked_classes[0], scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: class_1\n",
      "Similarity scores: {'class_1': 0.85881895, 'class_2': 0.65683764}\n"
     ]
    }
   ],
   "source": [
    "# Example support set with class labels and corresponding image paths\n",
    "support_set = {\n",
    "    \"class_1\": [\"cat1.jpg\", \"cat2.jpg\"],\n",
    "    \"class_2\": [\"dog1.jpg\", \"dog2.jpg\"],\n",
    "    # Add more classes as needed\n",
    "}\n",
    "\n",
    "# Define the path to the query image\n",
    "query_image_path = \"cattest.jpeg\"\n",
    "\n",
    "# Perform zero-shot classification\n",
    "predicted_class, similarity_scores = zero_shot_classification(support_set, query_image_path, model, processor)\n",
    "\n",
    "print(f\"Predicted class: {predicted_class}\")\n",
    "print(f\"Similarity scores: {similarity_scores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: class_1\n",
      "Similarity scores: {'class_1': 0.85881895, 'class_2': 0.65683764}\n"
     ]
    }
   ],
   "source": [
    "# Display the predicted class and similarity scores\n",
    "print(f\"Predicted class: {predicted_class}\")\n",
    "print(f\"Similarity scores: {similarity_scores}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
